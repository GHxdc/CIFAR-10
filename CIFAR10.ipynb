{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(0.4), # 随机水平翻转\n",
    "    transforms.RandomVerticalFlip(0.4), # 随机垂直翻转\n",
    "    transforms.ColorJitter(0.5,0.5,0.5,0.5), # 亮度、对比度、饱和度、色彩度\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 训练集\n",
    "trainset = datasets.CIFAR10(root='./CIFAR10', train=True, download=True, transform=transform)\n",
    "# 测试集\n",
    "testset = datasets.CIFAR10(root='./CIFAR10', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量读取数据\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=6, pin_memory=True)\n",
    "test_loader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=True, num_workers=6, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络模型\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()     \n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3,padding=1) \n",
    "        self.conv3 = nn.Conv2d(32, 32, 5)\n",
    "        self.pooling = nn.MaxPool2d(2)  \n",
    "        self.fc1 = nn.Linear(32*2*2, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)    \n",
    "        self.fc3 = nn.Linear(32, 10) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size=x.size(0)\n",
    "        x=F.relu(self.pooling(self.conv1(x)))\n",
    "        x=F.relu(self.pooling(self.conv2(x)))\n",
    "        x=F.relu(self.pooling(self.conv3(x)))\n",
    "        x=x.view(batch_size,-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model=Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # 交叉式损失函数\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.9) # 优化器5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :1 , Batch :  1563 , Loss : 0.0720\n",
      "Epoch :2 , Batch :  1563 , Loss : 0.0711\n",
      "Epoch :3 , Batch :  1563 , Loss : 0.0653\n",
      "Epoch :4 , Batch :  1563 , Loss : 0.0582\n",
      "Epoch :5 , Batch :  1563 , Loss : 0.0541\n",
      "Epoch :6 , Batch :  1563 , Loss : 0.0503\n",
      "Epoch :7 , Batch :  1563 , Loss : 0.0472\n",
      "Epoch :8 , Batch :  1563 , Loss : 0.0446\n",
      "Epoch :9 , Batch :  1563 , Loss : 0.0429\n",
      "lr : 0.0016000\n",
      "Epoch :10 , Batch :  1563 , Loss : 0.0406\n",
      "Epoch :11 , Batch :  1563 , Loss : 0.0393\n",
      "Epoch :12 , Batch :  1563 , Loss : 0.0382\n",
      "Epoch :13 , Batch :  1563 , Loss : 0.0372\n",
      "Epoch :14 , Batch :  1563 , Loss : 0.0366\n",
      "Epoch :15 , Batch :  1563 , Loss : 0.0358\n",
      "Epoch :16 , Batch :  1563 , Loss : 0.0351\n",
      "Epoch :17 , Batch :  1563 , Loss : 0.0345\n",
      "Epoch :18 , Batch :  1563 , Loss : 0.0340\n",
      "Epoch :19 , Batch :  1563 , Loss : 0.0336\n",
      "lr : 0.0012800\n",
      "Epoch :20 , Batch :  1563 , Loss : 0.0329\n",
      "Epoch :21 , Batch :  1563 , Loss : 0.0323\n",
      "Epoch :22 , Batch :  1563 , Loss : 0.0319\n",
      "Epoch :23 , Batch :  1563 , Loss : 0.0316\n",
      "Epoch :24 , Batch :  1563 , Loss : 0.0314\n",
      "Epoch :25 , Batch :  1563 , Loss : 0.0311\n",
      "Epoch :26 , Batch :  1563 , Loss : 0.0308\n",
      "Epoch :27 , Batch :  1563 , Loss : 0.0307\n",
      "Epoch :28 , Batch :  1563 , Loss : 0.0304\n",
      "Epoch :29 , Batch :  1563 , Loss : 0.0303\n",
      "lr : 0.0010240\n",
      "Epoch :30 , Batch :  1563 , Loss : 0.0295\n",
      "Epoch :31 , Batch :  1563 , Loss : 0.0292\n",
      "Epoch :32 , Batch :  1563 , Loss : 0.0292\n",
      "Epoch :33 , Batch :  1563 , Loss : 0.0288\n",
      "Epoch :34 , Batch :  1563 , Loss : 0.0288\n",
      "Epoch :35 , Batch :  1563 , Loss : 0.0287\n",
      "Epoch :36 , Batch :  1563 , Loss : 0.0285\n",
      "Epoch :37 , Batch :  1563 , Loss : 0.0285\n",
      "Epoch :38 , Batch :  1563 , Loss : 0.0283\n",
      "Epoch :39 , Batch :  1563 , Loss : 0.0281\n",
      "lr : 0.0008192\n",
      "Epoch :40 , Batch :  1563 , Loss : 0.0276\n",
      "Epoch :41 , Batch :  1563 , Loss : 0.0274\n",
      "Epoch :42 , Batch :  1563 , Loss : 0.0274\n",
      "Epoch :43 , Batch :  1563 , Loss : 0.0274\n",
      "Epoch :44 , Batch :  1563 , Loss : 0.0271\n",
      "Epoch :45 , Batch :  1563 , Loss : 0.0271\n",
      "Epoch :46 , Batch :  1563 , Loss : 0.0269\n",
      "Epoch :47 , Batch :  1563 , Loss : 0.0268\n",
      "Epoch :48 , Batch :  1563 , Loss : 0.0268\n",
      "Epoch :49 , Batch :  1563 , Loss : 0.0267\n",
      "lr : 0.0007373\n",
      "Epoch :50 , Batch :  1563 , Loss : 0.0265\n",
      "Epoch :51 , Batch :  1563 , Loss : 0.0264\n",
      "Epoch :52 , Batch :  1563 , Loss : 0.0263\n",
      "Epoch :53 , Batch :  1563 , Loss : 0.0262\n",
      "Epoch :54 , Batch :  1563 , Loss : 0.0261\n",
      "Epoch :55 , Batch :  1563 , Loss : 0.0262\n",
      "Epoch :56 , Batch :  1563 , Loss : 0.0262\n",
      "Epoch :57 , Batch :  1563 , Loss : 0.0258\n",
      "Epoch :58 , Batch :  1563 , Loss : 0.0259\n",
      "Epoch :59 , Batch :  1563 , Loss : 0.0259\n",
      "lr : 0.0006636\n",
      "Epoch :60 , Batch :  1563 , Loss : 0.0256\n",
      "Epoch :61 , Batch :  1563 , Loss : 0.0257\n",
      "Epoch :62 , Batch :  1563 , Loss : 0.0254\n",
      "Epoch :63 , Batch :  1563 , Loss : 0.0254\n",
      "Epoch :64 , Batch :  1563 , Loss : 0.0254\n",
      "Epoch :65 , Batch :  1563 , Loss : 0.0253\n",
      "Epoch :66 , Batch :  1563 , Loss : 0.0253\n",
      "Epoch :67 , Batch :  1563 , Loss : 0.0252\n",
      "Epoch :68 , Batch :  1563 , Loss : 0.0251\n",
      "Epoch :69 , Batch :  1563 , Loss : 0.0251\n",
      "lr : 0.0005972\n",
      "Epoch :70 , Batch :  1563 , Loss : 0.0248\n",
      "Epoch :71 , Batch :  1563 , Loss : 0.0248\n",
      "Epoch :72 , Batch :  1563 , Loss : 0.0248\n",
      "Epoch :73 , Batch :  1563 , Loss : 0.0248\n",
      "Epoch :74 , Batch :  1563 , Loss : 0.0246\n",
      "Epoch :75 , Batch :  1563 , Loss : 0.0248\n",
      "Epoch :76 , Batch :  1563 , Loss : 0.0245\n",
      "Epoch :77 , Batch :  1563 , Loss : 0.0245\n",
      "Epoch :78 , Batch :  1563 , Loss : 0.0244\n",
      "Epoch :79 , Batch :  1563 , Loss : 0.0245\n",
      "lr : 0.0005375\n",
      "Epoch :80 , Batch :  1563 , Loss : 0.0245\n",
      "Epoch :81 , Batch :  1563 , Loss : 0.0243\n",
      "Epoch :82 , Batch :  1563 , Loss : 0.0243\n",
      "Epoch :83 , Batch :  1563 , Loss : 0.0241\n",
      "Epoch :84 , Batch :  1563 , Loss : 0.0243\n",
      "Epoch :85 , Batch :  1563 , Loss : 0.0241\n",
      "Epoch :86 , Batch :  1563 , Loss : 0.0239\n",
      "Epoch :87 , Batch :  1563 , Loss : 0.0241\n",
      "Epoch :88 , Batch :  1563 , Loss : 0.0240\n",
      "Epoch :89 , Batch :  1563 , Loss : 0.0239\n",
      "lr : 0.0004837\n",
      "Epoch :90 , Batch :  1563 , Loss : 0.0239\n",
      "Epoch :91 , Batch :  1563 , Loss : 0.0237\n",
      "Epoch :92 , Batch :  1563 , Loss : 0.0237\n",
      "Epoch :93 , Batch :  1563 , Loss : 0.0237\n",
      "Epoch :94 , Batch :  1563 , Loss : 0.0238\n",
      "Epoch :95 , Batch :  1563 , Loss : 0.0237\n",
      "Epoch :96 , Batch :  1563 , Loss : 0.0235\n",
      "Epoch :97 , Batch :  1563 , Loss : 0.0235\n",
      "Epoch :98 , Batch :  1563 , Loss : 0.0237\n",
      "Epoch :99 , Batch :  1563 , Loss : 0.0235\n",
      "lr : 0.0004354\n",
      "Epoch :100 , Batch :  1563 , Loss : 0.0234\n",
      "Epoch :101 , Batch :  1563 , Loss : 0.0233\n",
      "Epoch :102 , Batch :  1563 , Loss : 0.0234\n",
      "Epoch :103 , Batch :  1563 , Loss : 0.0231\n",
      "Epoch :104 , Batch :  1563 , Loss : 0.0232\n",
      "Epoch :105 , Batch :  1563 , Loss : 0.0233\n",
      "Epoch :106 , Batch :  1563 , Loss : 0.0232\n",
      "Epoch :107 , Batch :  1563 , Loss : 0.0232\n",
      "Epoch :108 , Batch :  1563 , Loss : 0.0232\n",
      "Epoch :109 , Batch :  1563 , Loss : 0.0233\n",
      "lr : 0.0003918\n",
      "Epoch :110 , Batch :  1563 , Loss : 0.0229\n",
      "Epoch :111 , Batch :  1563 , Loss : 0.0231\n",
      "Epoch :112 , Batch :  1563 , Loss : 0.0230\n",
      "Epoch :113 , Batch :  1563 , Loss : 0.0230\n",
      "Epoch :114 , Batch :  1563 , Loss : 0.0230\n",
      "Epoch :115 , Batch :  1563 , Loss : 0.0229\n",
      "Epoch :116 , Batch :  1563 , Loss : 0.0229\n",
      "Epoch :117 , Batch :  1563 , Loss : 0.0229\n",
      "Epoch :118 , Batch :  1563 , Loss : 0.0229\n",
      "Epoch :119 , Batch :  1563 , Loss : 0.0228\n",
      "lr : 0.0003526\n",
      "Epoch :120 , Batch :  1563 , Loss : 0.0226\n",
      "Epoch :121 , Batch :  1563 , Loss : 0.0228\n",
      "Epoch :122 , Batch :  1563 , Loss : 0.0227\n",
      "Epoch :123 , Batch :  1563 , Loss : 0.0227\n",
      "Epoch :124 , Batch :  1563 , Loss : 0.0226\n",
      "Epoch :125 , Batch :  1563 , Loss : 0.0225\n",
      "Epoch :126 , Batch :  1563 , Loss : 0.0226\n",
      "Epoch :127 , Batch :  1563 , Loss : 0.0226\n",
      "Epoch :128 , Batch :  1563 , Loss : 0.0225\n",
      "Epoch :129 , Batch :  1563 , Loss : 0.0225\n",
      "lr : 0.0003174\n",
      "Epoch :130 , Batch :  1563 , Loss : 0.0224\n",
      "Epoch :131 , Batch :  1563 , Loss : 0.0224\n",
      "Epoch :132 , Batch :  1563 , Loss : 0.0225\n",
      "Epoch :133 , Batch :  1563 , Loss : 0.0223\n",
      "Epoch :134 , Batch :  1563 , Loss : 0.0223\n",
      "Epoch :135 , Batch :  1563 , Loss : 0.0223\n",
      "Epoch :136 , Batch :  1563 , Loss : 0.0224\n",
      "Epoch :137 , Batch :  1563 , Loss : 0.0222\n",
      "Epoch :138 , Batch :  1563 , Loss : 0.0223\n",
      "Epoch :139 , Batch :  1563 , Loss : 0.0222\n",
      "lr : 0.0002856\n",
      "Epoch :140 , Batch :  1563 , Loss : 0.0223\n",
      "Epoch :141 , Batch :  1563 , Loss : 0.0222\n",
      "Epoch :142 , Batch :  1563 , Loss : 0.0220\n",
      "Epoch :143 , Batch :  1563 , Loss : 0.0223\n",
      "Epoch :144 , Batch :  1563 , Loss : 0.0221\n",
      "Epoch :145 , Batch :  1563 , Loss : 0.0221\n",
      "Epoch :146 , Batch :  1563 , Loss : 0.0222\n",
      "Epoch :147 , Batch :  1563 , Loss : 0.0221\n",
      "Epoch :148 , Batch :  1563 , Loss : 0.0220\n",
      "Epoch :149 , Batch :  1563 , Loss : 0.0222\n",
      "lr : 0.0002571\n",
      "Epoch :150 , Batch :  1563 , Loss : 0.0220\n"
     ]
    }
   ],
   "source": [
    "# 定义轮数\n",
    "EPOCHS = 150\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    if (epoch+1) % 10 == 0:  # 每迭代次，更新一次学习率        \n",
    "        for params in optimizer.param_groups:\n",
    "            if params['lr'] > 0.001:\n",
    "                params['lr'] *= 0.8\n",
    "            else:\n",
    "                params['lr'] *= 0.9\n",
    "            print(\"lr : %.7f\"%(params['lr']))\n",
    "            \n",
    "    train_loss = 0.0\n",
    "    for i, (datas, labels) in enumerate(train_loader):\n",
    "        # 梯度置零\n",
    "        optimizer.zero_grad()\n",
    "        # 训练\n",
    "        outputs = model(datas)\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 参数更新\n",
    "        optimizer.step()\n",
    "        # 累计损失\n",
    "        train_loss += loss.item()\n",
    "    # 打印信息\n",
    "    print(\"Epoch :%d , Batch : %5d , Loss : %.4f\"%(epoch+1, i+1, train_loss/len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "PATH = './cifar_model.pth'\n",
    "\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型\n",
    "\n",
    "model = Net()\n",
    "path = './cifar_model.pth'\n",
    "model.load_state_dict(torch.load(path)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在10000张测试集图片上的准确率：70.280%\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i , (datas, labels) in enumerate(test_loader):\n",
    "        # 输出\n",
    "        outputs = model(datas) # outputs.data.shape --> torch.Size([128, 10])\n",
    "        _, predicted = torch.max(outputs.data, dim=1) # 第一个是值的张量，第二个是序号的张量\n",
    "        # 累计数据量\n",
    "        total += labels.size(0)  # labels.size() --> torch.Size([128]) , labels.size(0) --> 128\n",
    "        # 比较有多少个预测正确\n",
    "        correct += (predicted == labels).sum() # 相同为1，不同为0，利用sum()求总和\n",
    "    print(\"在10000张测试集图片上的准确率：{:.3f}%\".format(correct / total * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
